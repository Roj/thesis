{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_graph(fn):\n",
    "    with open(fn, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "filenames = [fn for fn in os.listdir(\"../graphs/\") if \".pkl\" in fn]\n",
    "graphs = [load_graph(\"../graphs/\"+fn) for fn in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../names_groups.pkl\", \"rb\")  as f:\n",
    "    names, groups = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 1 proteins without group'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import biograph.groupfolds\n",
    "protein_group_dict = biograph.groupfolds.CDHitGroup.get_protein_groups(names, groups)\n",
    "protein_ids = []\n",
    "for graph in graphs:\n",
    "    node_idx = list(graph.nodes)[0]\n",
    "    protein_ids.append(graph.nodes[node_idx][\"full_id\"][0])\n",
    "protein_groups = [protein_group_dict.get(pdbid, -1) for pdbid in protein_ids]\n",
    "\"There are {} proteins without group\".format(len(list(filter(lambda g: g==-1, protein_groups))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 0.02368611581263995, {'5A99_A': 247})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notin = 0\n",
    "total = 0\n",
    "chainnot = {}\n",
    "for graph in graphs:\n",
    "    for node_idx in graph.nodes:\n",
    "        total+=1\n",
    "        chain = graph.nodes[node_idx][\"chain\"]\n",
    "        if chain not in groups:\n",
    "            notin+=1\n",
    "            graph.nodes[node_idx][\"group\"] = None\n",
    "            chainnot[chain] = chainnot.get(chain, 0) + 1\n",
    "        else:\n",
    "            graph.nodes[node_idx][\"group\"] = chain\n",
    "notin, notin/total *100, chainnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_interior(graph):\n",
    "    edges_to_remove = set()\n",
    "    nodes_to_remove = set()\n",
    "    for node_idx, adj_dict in graph.adjacency():\n",
    "        neighbors_not_in_surf = [k for k,v in adj_dict.items() if not v[\"in_surf\"]]\n",
    "        edges_to_remove.update([\n",
    "            (node_idx, neighbor)  if node_idx < neighbor else (neighbor, node_idx) \n",
    "            for neighbor in neighbors_not_in_surf])\n",
    "        if len(adj_dict) == len(neighbors_not_in_surf):\n",
    "            nodes_to_remove.add(node_idx)\n",
    "    edges_before = graph.number_of_edges()\n",
    "    nodes_before = graph.number_of_nodes()\n",
    "    for edge in edges_to_remove:\n",
    "        graph.remove_edge(*edge)\n",
    "    for idx in nodes_to_remove:\n",
    "        graph.remove_node(idx)\n",
    "    return graph\n",
    "#edges_before, graph.number_of_edges(), nodes_before, graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [remove_interior(graph) for graph in graphs]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"1A3N\" in names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].nodes == graphs[0].nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biograph.constants\n",
    "index_amino = {code3:i for i, code3 in enumerate(biograph.constants.AMINOACIDS_3)}\n",
    "index_amino[\"UNK\"] = len(index_amino)\n",
    "num_amino = len(index_amino)\n",
    "\n",
    "# Features are aminoacid type, bfactor and x,y,z coord.\n",
    "all_features = []\n",
    "for graph in graphs:\n",
    "    features = np.zeros((graph.number_of_nodes(), num_amino + 4))\n",
    "    for i, node_idx in enumerate(graph.nodes):\n",
    "        node = graph.nodes[node_idx]\n",
    "        #features[i, 0:num_amino+4] = 1\n",
    "        features[i, index_amino[node[\"resname\"]]] = 1\n",
    "        features[i, num_amino] = node[\"bfactor\"]\n",
    "        features[i, num_amino+1:num_amino+4] = node[\"coord\"]\n",
    "        \n",
    "    all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([200., 507., 292.,  95.,  64.,  41.,  13.,  10.,   1.,   5.]),\n",
       " array([  61.,  186.,  311.,  436.,  561.,  686.,  811.,  936., 1061.,\n",
       "        1186., 1311.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([features.shape[0] for features in all_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 1218)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features), len([features for features in all_features if features.shape[0]<1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adj = [nx.adjacency_matrix(graph) for graph in graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touches_ligand(x):\n",
    "    return x <= 4 or (x<=6 and np.random.binomial(1, 1-(x-4)/2) == 1)\n",
    "\n",
    "class_balance = []\n",
    "all_targets = []\n",
    "for graph in graphs:\n",
    "    targets = np.zeros((graph.number_of_nodes()))\n",
    "    for i, node_idx in enumerate(graph.nodes):\n",
    "        distance = graph.nodes[node_idx][\"distance\"]\n",
    "        targets[i] = 1 if touches_ligand(distance) else 0\n",
    "    class_balance.append(targets.sum() / (targets.shape[0]- targets.sum()))\n",
    "    all_targets.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<322x322 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1944 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_adj[0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and cast to float32 (default for tf)\n",
    "keep = [features.shape[0]<1000 for features in all_features]\n",
    "all_features = [features.astype(np.float32) for i, features in enumerate(all_features) if keep[i]]\n",
    "all_adj = [adj.astype(np.float32) for i, adj in enumerate(all_adj) if keep[i]]\n",
    "all_targets = [targets.astype(np.float32) for i, targets in enumerate(all_targets) if keep[i]]\n",
    "protein_groups = [g for i, g in enumerate(protein_groups) if keep[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For every non-contact point there are 0.028800538396223152 contact points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.7215731262558"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_positive_weight = 1/(sum(class_balance)/len(class_balance))\n",
    "print(\"For every non-contact point there are {} contact points\".format(\n",
    "    sum(class_balance)/len(class_balance)))\n",
    "fair_positive_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx\n",
    "\n",
    "class Laplacian:\n",
    "    @staticmethod\n",
    "    def from_adjacency(adj):\n",
    "        adj = adj + sp.eye(adj.shape[0])\n",
    "        \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "        return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_adj = [sparse_to_tuple(Laplacian.from_adjacency(adj)) \n",
    "            for adj in all_adj]\n",
    "#all_features = [preprocess_features(sp.lil_matrix(features))\n",
    "#            for features in all_features]\n",
    "\n",
    "nb_nodes_per_graph = [adj[2][1] for adj in all_adj]\n",
    "nb_nodes = max(map(lambda adj: adj[2][1], all_adj))\n",
    "nb_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sparse matrices the same size\n",
    "for i, adj_tuple in enumerate(all_adj):\n",
    "    #adj_tuple[2] is the shape, and we want it to be always the same..\n",
    "    all_adj[i] = (adj_tuple[0], adj_tuple[1], (nb_nodes, nb_nodes))\n",
    "\n",
    "# Make features the same size as well via padding\n",
    "\n",
    "for i, features in enumerate(all_features):\n",
    "    amount = nb_nodes-features.shape[0]\n",
    "    all_features[i] = np.pad(features, ((0,amount), (0,0)))\n",
    "    \n",
    "for i, target in enumerate(all_targets):\n",
    "    amount = nb_nodes-target.shape[0]\n",
    "    all_targets[i] = np.pad(target, (0,amount))\n",
    "\n",
    "masks_all = []\n",
    "for n in nb_nodes_per_graph:\n",
    "    mask = np.pad(np.ones(n), (0, nb_nodes - n)).astype(np.float32)\n",
    "    masks_all.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id=\"root\"></div>\n",
       "    <script>\n",
       "      (function() {\n",
       "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
       "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
       "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
       "        function fixUpTensorboard(root) {\n",
       "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
       "          // Disable the fragment manipulation behavior in Colab. Not\n",
       "          // only is the behavior not useful (as the iframe's location\n",
       "          // is not visible to the user), it causes TensorBoard's usage\n",
       "          // of `window.replace` to navigate away from the page and to\n",
       "          // the `localhost:<port>` URL specified by the base URI, which\n",
       "          // in turn causes the frame to (likely) crash.\n",
       "          tftb.removeAttribute(\"use-hash\");\n",
       "        }\n",
       "        function executeAllScripts(root) {\n",
       "          // When `script` elements are inserted into the DOM by\n",
       "          // assigning to an element's `innerHTML`, the scripts are not\n",
       "          // executed. Thus, we manually re-insert these scripts so that\n",
       "          // TensorBoard can initialize itself.\n",
       "          for (const script of root.querySelectorAll(\"script\")) {\n",
       "            const newScript = document.createElement(\"script\");\n",
       "            newScript.type = script.type;\n",
       "            newScript.textContent = script.textContent;\n",
       "            root.appendChild(newScript);\n",
       "            script.remove();\n",
       "          }\n",
       "        }\n",
       "        function setHeight(root, height) {\n",
       "          // We set the height dynamically after the TensorBoard UI has\n",
       "          // been initialized. This avoids an intermediate state in\n",
       "          // which the container plus the UI become taller than the\n",
       "          // final width and cause the Colab output frame to be\n",
       "          // permanently resized, eventually leading to an empty\n",
       "          // vertical gap below the TensorBoard UI. It's not clear\n",
       "          // exactly what causes this problematic intermediate state,\n",
       "          // but setting the height late seems to fix it.\n",
       "          root.style.height = `${height}px`;\n",
       "        }\n",
       "        const root = document.getElementById(\"root\");\n",
       "        fetch(\".\")\n",
       "          .then((x) => x.text())\n",
       "          .then((html) => void (root.innerHTML = html))\n",
       "          .then(() => fixUpTensorboard(root))\n",
       "          .then(() => executeAllScripts(root))\n",
       "          .then(() => setHeight(root, 800));\n",
       "      })();\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gcn.gcn' from '/home/joaquintz/research/thesis/src/gcn/gcn.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gcn.gcn as gcn\n",
    "from importlib import reload\n",
    "reload(gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.from_tensor_slices = lambda a: a \n",
    "feats = all_features\n",
    "supps = [tf.sparse.SparseTensor(indices, values.astype(np.float32), dense_shape)\n",
    "            for indices, values, dense_shape in all_adj]\n",
    "targs = all_targets\n",
    "masks = masks_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gcn.GraphConvolutionalNetwork(all_features[0].shape, 1, all_adj[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting weights..\n",
      "Start of epoch 0\n",
      "Epoch 0:\n",
      "\tTRAIN loss 0.38, auc 0.59, recall 0.20, precision 0.03\n",
      "\tVAL loss 0.37 auc 0.59 recall 0.04 precision 0.03\n",
      "Confusion matrix(TRAIN):\n",
      "[[259536  48380]\n",
      " [  6617   2438]]\n",
      "Confusion matrix(VAL):\n",
      "[[70539  2162]\n",
      " [ 1609    72]]\n",
      "Start of epoch 1\n",
      "Epoch 1:\n",
      "\tTRAIN loss 0.37, auc 0.61, recall 0.24, precision 0.03\n",
      "\tVAL loss 0.36 auc 0.61 recall 0.06 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[256662  51254]\n",
      " [  6347   2708]]\n",
      "Confusion matrix(VAL):\n",
      "[[70243  2458]\n",
      " [ 1583    98]]\n",
      "Start of epoch 2\n",
      "Epoch 2:\n",
      "\tTRAIN loss 0.37, auc 0.62, recall 0.32, precision 0.03\n",
      "\tVAL loss 0.36 auc 0.62 recall 0.12 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[241428  66488]\n",
      " [  5834   3221]]\n",
      "Confusion matrix(VAL):\n",
      "[[67861  4840]\n",
      " [ 1481   200]]\n",
      "Start of epoch 3\n",
      "Epoch 3:\n",
      "\tTRAIN loss 0.37, auc 0.63, recall 0.38, precision 0.03\n",
      "\tVAL loss 0.36 auc 0.62 recall 0.17 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[231908  76008]\n",
      " [  5395   3660]]\n",
      "Confusion matrix(VAL):\n",
      "[[66100  6601]\n",
      " [ 1394   287]]\n",
      "Start of epoch 4\n",
      "Epoch 4:\n",
      "\tTRAIN loss 0.37, auc 0.64, recall 0.41, precision 0.04\n",
      "\tVAL loss 0.36 auc 0.62 recall 0.19 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[228413  79503]\n",
      " [  5189   3866]]\n",
      "Confusion matrix(VAL):\n",
      "[[64968  7733]\n",
      " [ 1357   324]]\n",
      "Start of epoch 5\n",
      "Epoch 5:\n",
      "\tTRAIN loss 0.37, auc 0.64, recall 0.44, precision 0.04\n",
      "\tVAL loss 0.36 auc 0.62 recall 0.22 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[223849  84067]\n",
      " [  4971   4084]]\n",
      "Confusion matrix(VAL):\n",
      "[[63768  8933]\n",
      " [ 1314   367]]\n",
      "Start of epoch 6\n",
      "Epoch 6:\n",
      "\tTRAIN loss 0.37, auc 0.66, recall 0.48, precision 0.04\n",
      "\tVAL loss 0.36 auc 0.64 recall 0.26 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[222265  85651]\n",
      " [  4687   4368]]\n",
      "Confusion matrix(VAL):\n",
      "[[63183  9518]\n",
      " [ 1236   445]]\n",
      "Start of epoch 7\n",
      "Epoch 7:\n",
      "\tTRAIN loss 0.36, auc 0.68, recall 0.51, precision 0.04\n",
      "\tVAL loss 0.36 auc 0.65 recall 0.29 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[223154  84762]\n",
      " [  4437   4618]]\n",
      "Confusion matrix(VAL):\n",
      "[[62422 10279]\n",
      " [ 1201   480]]\n",
      "Start of epoch 8\n",
      "Epoch 8:\n",
      "\tTRAIN loss 0.36, auc 0.70, recall 0.54, precision 0.04\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.34 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[224733  83183]\n",
      " [  4221   4834]]\n",
      "Confusion matrix(VAL):\n",
      "[[60386 12315]\n",
      " [ 1105   576]]\n",
      "Start of epoch 9\n",
      "Epoch 9:\n",
      "\tTRAIN loss 0.36, auc 0.71, recall 0.58, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.41 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[223271  84645]\n",
      " [  3992   5063]]\n",
      "Confusion matrix(VAL):\n",
      "[[56993 15708]\n",
      " [  997   684]]\n",
      "Start of epoch 10\n",
      "Epoch 10:\n",
      "\tTRAIN loss 0.35, auc 0.72, recall 0.59, precision 0.05\n",
      "\tVAL loss 0.35 auc 0.67 recall 0.44 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[225745  82171]\n",
      " [  3883   5172]]\n",
      "Confusion matrix(VAL):\n",
      "[[56761 15940]\n",
      " [  935   746]]\n",
      "Start of epoch 11\n",
      "Epoch 11:\n",
      "\tTRAIN loss 0.35, auc 0.73, recall 0.61, precision 0.05\n",
      "\tVAL loss 0.35 auc 0.66 recall 0.45 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[225042  82874]\n",
      " [  3767   5288]]\n",
      "Confusion matrix(VAL):\n",
      "[[55904 16797]\n",
      " [  928   753]]\n",
      "Start of epoch 12\n",
      "Epoch 12:\n",
      "\tTRAIN loss 0.34, auc 0.74, recall 0.61, precision 0.05\n",
      "\tVAL loss 0.35 auc 0.67 recall 0.47 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[228176  78748]\n",
      " [  2792   4279]]\n",
      "Confusion matrix(VAL):\n",
      "[[56194 16507]\n",
      " [  886   795]]\n",
      "Start of epoch 13\n",
      "Epoch 13:\n",
      "\tTRAIN loss 0.34, auc 0.74, recall 0.61, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.47 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[227101  79823]\n",
      " [  2761   4310]]\n",
      "Confusion matrix(VAL):\n",
      "[[56084 16617]\n",
      " [  893   788]]\n",
      "Start of epoch 14\n",
      "Epoch 14:\n",
      "\tTRAIN loss 0.34, auc 0.75, recall 0.61, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.48 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[228121  78803]\n",
      " [  2725   4346]]\n",
      "Confusion matrix(VAL):\n",
      "[[55233 17468]\n",
      " [  873   808]]\n",
      "Start of epoch 15\n",
      "Epoch 15:\n",
      "\tTRAIN loss 0.34, auc 0.75, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.48 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[227855  80061]\n",
      " [  3705   5350]]\n",
      "Confusion matrix(VAL):\n",
      "[[55044 17657]\n",
      " [  880   801]]\n",
      "Start of epoch 16\n",
      "Epoch 16:\n",
      "\tTRAIN loss 0.33, auc 0.75, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.48 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[229026  77898]\n",
      " [  2698   4373]]\n",
      "Confusion matrix(VAL):\n",
      "[[55368 17333]\n",
      " [  871   810]]\n",
      "Start of epoch 17\n",
      "Epoch 17:\n",
      "\tTRAIN loss 0.33, auc 0.75, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.47 precision 0.04\n",
      "Confusion matrix(TRAIN):\n",
      "[[228657  78267]\n",
      " [  2718   4353]]\n",
      "Confusion matrix(VAL):\n",
      "[[55643 17058]\n",
      " [  887   794]]\n",
      "Start of epoch 18\n",
      "Epoch 18:\n",
      "\tTRAIN loss 0.33, auc 0.75, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[229440  77484]\n",
      " [  2698   4373]]\n",
      "Confusion matrix(VAL):\n",
      "[[55629 17072]\n",
      " [  872   809]]\n",
      "Start of epoch 19\n",
      "Epoch 19:\n",
      "\tTRAIN loss 0.33, auc 0.75, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.47 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[229295  77629]\n",
      " [  2698   4373]]\n",
      "Confusion matrix(VAL):\n",
      "[[56161 16540]\n",
      " [  890   791]]\n",
      "Start of epoch 20\n",
      "Epoch 20:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.49 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[230446  76478]\n",
      " [  2716   4355]]\n",
      "Confusion matrix(VAL):\n",
      "[[55512 17189]\n",
      " [  865   816]]\n",
      "Start of epoch 21\n",
      "Epoch 21:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.47 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[229066  77858]\n",
      " [  2676   4395]]\n",
      "Confusion matrix(VAL):\n",
      "[[56181 16520]\n",
      " [  883   798]]\n",
      "Start of epoch 22\n",
      "Epoch 22:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.47 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[230427  76497]\n",
      " [  2680   4391]]\n",
      "Confusion matrix(VAL):\n",
      "[[56687 16014]\n",
      " [  886   795]]\n",
      "Start of epoch 23\n",
      "Epoch 23:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.66 recall 0.49 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[230814  76110]\n",
      " [  2690   4381]]\n",
      "Confusion matrix(VAL):\n",
      "[[55240 17461]\n",
      " [  851   830]]\n",
      "Start of epoch 24\n",
      "Epoch 24:\n",
      "\tTRAIN loss 0.33, auc 0.75, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.35 auc 0.67 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[229496  77428]\n",
      " [  2694   4377]]\n",
      "Confusion matrix(VAL):\n",
      "[[56276 16425]\n",
      " [  880   801]]\n",
      "Start of epoch 25\n",
      "Epoch 25:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.63, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[230024  76900]\n",
      " [  2651   4420]]\n",
      "Confusion matrix(VAL):\n",
      "[[56264 16437]\n",
      " [  867   814]]\n",
      "Start of epoch 26\n",
      "Epoch 26:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[230425  76847]\n",
      " [  3028   4739]]\n",
      "Confusion matrix(VAL):\n",
      "[[56484 16217]\n",
      " [  877   804]]\n",
      "Start of epoch 27\n",
      "Epoch 27:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.06\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[231787  88851]\n",
      " [ 16399  18100]]\n",
      "Confusion matrix(VAL):\n",
      "[[56280 18977]\n",
      " [ 3426  3367]]\n",
      "Start of epoch 28\n",
      "Epoch 28:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.05\n",
      "\tVAL loss 0.35 auc 0.67 recall 0.49 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[231659  97970]\n",
      " [ 25398  27083]]\n",
      "Confusion matrix(VAL):\n",
      "[[55883 19374]\n",
      " [ 3417  3376]]\n",
      "Start of epoch 29\n",
      "Epoch 29:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.06\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.49 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[232279  96938]\n",
      " [ 24975  26682]]\n",
      "Confusion matrix(VAL):\n",
      "[[56187 19070]\n",
      " [ 3418  3375]]\n",
      "Start of epoch 30\n",
      "Epoch 30:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.63, precision 0.06\n",
      "\tVAL loss 0.35 auc 0.67 recall 0.47 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[231054  98163]\n",
      " [ 24943  26714]]\n",
      "Confusion matrix(VAL):\n",
      "[[56768 19043]\n",
      " [ 3995  3906]]\n",
      "Start of epoch 31\n",
      "Epoch 31:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.06\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.46 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[232046  97171]\n",
      " [ 24989  26668]]\n",
      "Confusion matrix(VAL):\n",
      "[[57360 17897]\n",
      " [ 3458  3335]]\n",
      "Start of epoch 32\n",
      "Epoch 32:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.06\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[232666  96963]\n",
      " [ 25409  27072]]\n",
      "Confusion matrix(VAL):\n",
      "[[56693 18564]\n",
      " [ 3429  3364]]\n",
      "Start of epoch 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\n",
      "\tTRAIN loss 0.33, auc 0.76, recall 0.62, precision 0.06\n",
      "\tVAL loss 0.36 auc 0.67 recall 0.48 precision 0.05\n",
      "Confusion matrix(TRAIN):\n",
      "[[233257  95960]\n",
      " [ 24998  26659]]\n",
      "Confusion matrix(VAL):\n",
      "[[56571 18686]\n",
      " [ 3429  3364]]\n",
      "Start of epoch 34\n"
     ]
    }
   ],
   "source": [
    "model.fit_cv_groups((feats, supps, targs, masks), protein_groups,\n",
    "                   positive_weight=34, epochs=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protein_ids), len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(data, train_perc, val_perc):\n",
    "    num_train = int(len(data) * train_perc)\n",
    "    num_val = int(len(data) * val_perc)\n",
    "    return data[:num_train], data[num_train:num_train+num_val], data[num_train+num_val:]\n",
    "\n",
    "features_train, features_val, features_test = split_list(all_features, 0.70, 0.15)\n",
    "adj_train, adj_val, adj_test = split_list(all_adj, 0.70, 0.15)\n",
    "y_train, y_val, y_test = split_list(all_targets, 0.70, 0.15)\n",
    "nodes_train, nodes_val, nodes_test = split_list(nb_nodes_per_graph, 0.70, 0.15)\n",
    "masks_train, masks_val, masks_test = split_list(masks_all, 0.70, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "tf.data.Dataset.from_tensor_slices = lambda a: a \n",
    "feats_tr = tf.data.Dataset.from_tensor_slices(features_train)\n",
    "supps_tr = [tf.sparse.SparseTensor(indices, values.astype(np.float32), dense_shape)\n",
    "            for indices, values, dense_shape in adj_train]\n",
    "targs_tr = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "masks_tr = tf.data.Dataset.from_tensor_slices(masks_train)\n",
    "\n",
    "feats_vl = tf.data.Dataset.from_tensor_slices(features_val)\n",
    "supps_vl = [tf.sparse.SparseTensor(indices, values.astype(np.float32), dense_shape)\n",
    "            for indices, values, dense_shape in adj_val]\n",
    "targs_vl = tf.data.Dataset.from_tensor_slices(y_val)\n",
    "masks_vl = tf.data.Dataset.from_tensor_slices(masks_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " tensorflow.python.framework.sparse_tensor.SparseTensor,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feats_tr[0]), type(supps_tr[0]), type(targs_tr[0]), type(masks_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " tensorflow.python.framework.sparse_tensor.SparseTensor,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feats[0]), type(supps[0]), type(targs[0]), type(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gcn.GraphConvolutionalNetwork(features_train[0].shape, 1, adj_train[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Epoch 0:\n",
      "\tTRAIN loss 0.38, auc 0.59, recall 0.15, precision 0.03\n",
      "\tVAL loss 0.39 auc 0.59 recall 0.33 precision 0.03\n",
      "Confusion matrix(TRAIN):\n",
      "[[230182  35424]\n",
      " [  7864   3468]]\n",
      "Confusion matrix(VAL):\n",
      "[[42844 15159]\n",
      " [  919   460]]\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-41382e68b005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit((feats_tr, targs_tr, supps_tr, masks_tr), \n\u001b[1;32m      2\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0mfeats_vl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs_vl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupps_vl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_vl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=100, positive_weight=34)\n\u001b[0m",
      "\u001b[0;32m~/research/thesis/src/gcn/gcn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_zip, val_zip, positive_weight, epochs, verbose)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mỹ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mtrain_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mỹ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mtrain_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mỹ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m  \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     return distributed_training_utils.call_replica_local_fn(\n\u001b[0;32m--> 196\u001b[0;31m         replica_local_fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36mcall_replica_local_fn\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mreplica_local_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplica_local_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;34m\"\"\"Updates the state of the metric in a replica-local context.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m   1926\u001b[0m           \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m           \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m           label_weights=label_weights)\n\u001b[0m\u001b[1;32m   1929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minterpolate_pr_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[0;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[1;32m    438\u001b[0m       update_ops.append(\n\u001b[1;32m    439\u001b[0m           weighted_assign_add(label, pred, weights_tiled,\n\u001b[0;32m--> 440\u001b[0;31m                               variables_to_update[matrix_cond]))\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mweighted_assign_add\u001b[0;34m(label, pred, weights, var)\u001b[0m\n\u001b[1;32m    411\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mweighted_assign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     label_and_pred = math_ops.cast(\n\u001b[0;32m--> 413\u001b[0;31m         math_ops.logical_and(label, pred), dtype=dtypes.float32)\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0mlabel_and_pred\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   1961\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[1;32m   1963\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit((feats_tr, targs_tr, supps_tr, masks_tr), \n",
    "          (feats_vl, targs_vl, supps_vl, masks_vl), \n",
    "          epochs=100, positive_weight=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights[0].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "all_predicted = []\n",
    "all_real = []\n",
    "for x, y, L, mask in zip(feats_vl, targs_vl, supps_vl, masks_vl):\n",
    "    ỹ = model(x, L)\n",
    "    ỹ = tf.reshape(ỹ, [-1])\n",
    "    all_real.append(y)\n",
    "    all_predicted.append(ỹ.numpy())\n",
    "\n",
    "real = np.concatenate(all_real)\n",
    "predicted = np.concatenate(all_predicted)\n",
    "\n",
    "roc_auc_score(real, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred_classes = np.copy(predicted)\n",
    "pred_classes[pred_classes > 0.5] = 1\n",
    "pred_classes[pred_classes <= 0.5] = 0\n",
    "confusion_matrix(real, pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ỹ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater = tf.math.greater(ỹ, 0.5)\n",
    "tf.cast(tf.math.greater(ỹ, 0.5), tf.int32)  # [1, 2], dtype=tf.int32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tf.Tensor([[0,0],[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.conf_matrix + tf.math.confusion_matrix(y, ỹ, weights=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
